{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4a68d3c6-0885-44ea-865a-e10b840bb05a",
      "metadata": {
        "id": "4a68d3c6-0885-44ea-865a-e10b840bb05a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import re\n",
        "import pathlib\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from keras.layers import TextVectorization\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hemingway's Haiku\n",
        "\n",
        "### Generating Haiku poems with Hemingway's writing\n",
        "\n",
        "> A haiku is a short, unrhymed Japanese poem that is written in three lines of five, seven, and five syllables, respectively"
      ],
      "metadata": {
        "id": "OyxVkC4Czz2Y"
      },
      "id": "OyxVkC4Czz2Y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Workflow\n",
        "1. Create a simple text generating model (based on DLWP and provided notebooks)\n",
        "2. Evaluate the model\n",
        "3. Improving the model by implementing different methods\n",
        "4. Evaluate generated text\n",
        "5. Back to step 3"
      ],
      "metadata": {
        "id": "T9nrGp-Pzuui"
      },
      "id": "T9nrGp-Pzuui"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Simple text generating model"
      ],
      "metadata": {
        "id": "Q3eo7otpBdug"
      },
      "id": "Q3eo7otpBdug"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b574da1b-3021-49fa-9140-54495c1cc013",
      "metadata": {
        "id": "b574da1b-3021-49fa-9140-54495c1cc013",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef79416-9a5c-4187-ba95-0d9b8833bc2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 2  4  7  3  2 10  7  6 11  4  2  7  5 23 23 18  2 13  8 20  3  2  6 20\n",
            "  2 20 11  5  9 19  8 10  2 17  5 19  6 17 21  3 11  2  8  4  2 15  5 10\n",
            "  2  9  6 15  2 13 14  9 19  7  2  4  8 17  3  2  5  9 12  2  4  7  3 18\n",
            "  2 15  3 11  3  2  5 13 13  2 10  8  4  4  8  9 16  2 14  9 12  3 11  2\n",
            "  4  7  3  2 12], shape=(101,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "# open text file of Hemingway's text\n",
        "with open(\"../content/hemingwayshorts.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read().lower()\n",
        "text = re.sub(r\"[^\\w\\s]\", \"\", text)  # remove punctuation\n",
        "\n",
        "# tokenizer layer setup\n",
        "text_vectorization = tf.keras.layers.TextVectorization(\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    split=\"character\",\n",
        "    output_mode=\"int\",\n",
        ")\n",
        "\n",
        "text_vectorization.adapt([text])\n",
        "TOKEN_INDEX = dict(enumerate(text_vectorization.get_vocabulary()))\n",
        "VOCAB_SIZE = len(text_vectorization.get_vocabulary())   # retrieve the vocab size afterwards\n",
        "\n",
        "lm_dataset_raw = tf.data.Dataset.from_tensor_slices([text])\n",
        "\n",
        "lm_dataset_tok = lm_dataset_raw.map(text_vectorization)\n",
        "\n",
        "for t in lm_dataset_tok:\n",
        "    # print(t)\n",
        "    DATASET_LENGTH = t.shape[0]\n",
        "\n",
        "# tokenizing\n",
        "lm_dataset_flat = lm_dataset_tok.flat_map(\n",
        "    lambda x: tf.data.Dataset.from_tensor_slices(x)\n",
        ")\n",
        "\n",
        "SEQUENCE_LENGTH = 100\n",
        "\n",
        "lm_dataset_seqs = lm_dataset_flat.batch(\n",
        "    SEQUENCE_LENGTH + 1,\n",
        "    drop_remainder=True\n",
        ")\n",
        "\n",
        "for t in lm_dataset_seqs.take(1):\n",
        "    print(t)\n",
        "\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "lm_dataset_batched = (\n",
        "    lm_dataset_seqs\n",
        "        .repeat()\n",
        "        .shuffle(BUFFER_SIZE)\n",
        "        .batch(BATCH_SIZE, drop_remainder=True)\n",
        "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# for t in lm_dataset_batched.take(1):\n",
        "#     print(t.shape)\n",
        "\n",
        "def prepare_lm_dataset(tokens_batch):\n",
        "    x = tokens_batch[:, :-1]  # [a b c d e f g] the model predicts top to bottom,\n",
        "    y = tokens_batch[:, 1:]   # [b c d e f g h] a → b, a b → c, a b c → d, ..., in one go!\n",
        "    return x, y\n",
        "\n",
        "lm_dataset = lm_dataset_batched.map(prepare_lm_dataset, num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "328108dd-c2dc-4804-930d-7442b927afef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "328108dd-c2dc-4804-930d-7442b927afef",
        "outputId": "823f50bd-1aaa-4f9b-dfa2-2ebc0ad85b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "tf.Tensor(\n",
            "[[27 24 27  9  7 24 20 23 30  6]\n",
            " [44  1 42 29  3 16 18  6 44 12]], shape=(2, 10), dtype=int32)\n",
            "\n",
            "i:\n",
            "[[0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]\n",
            " [9]]\n",
            "\n",
            "j:\n",
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "\n",
            "Is i >= j? Boolean cast to ints. (Note the broadcasting)\n",
            "\n",
            "tf.Tensor(\n",
            "[[1 0 0 0 0 0 0 0 0 0]\n",
            " [1 1 0 0 0 0 0 0 0 0]\n",
            " [1 1 1 0 0 0 0 0 0 0]\n",
            " [1 1 1 1 0 0 0 0 0 0]\n",
            " [1 1 1 1 1 0 0 0 0 0]\n",
            " [1 1 1 1 1 1 0 0 0 0]\n",
            " [1 1 1 1 1 1 1 0 0 0]\n",
            " [1 1 1 1 1 1 1 1 0 0]\n",
            " [1 1 1 1 1 1 1 1 1 0]\n",
            " [1 1 1 1 1 1 1 1 1 1]], shape=(10, 10), dtype=int32)\n",
            "\n",
            "We want mask to have the same dims as input, using `tf.tile`.\n",
            "Creating the right multiplier for it:\n",
            "\n",
            "tf.Tensor([2 1 1], shape=(3,), dtype=int32)\n",
            "\n",
            "Final mask with batch dimensions:\n",
            "\n",
            "tf.Tensor(\n",
            "[[[1 0 0 0 0 0 0 0 0 0]\n",
            "  [1 1 0 0 0 0 0 0 0 0]\n",
            "  [1 1 1 0 0 0 0 0 0 0]\n",
            "  [1 1 1 1 0 0 0 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0 0 0]\n",
            "  [1 1 1 1 1 1 0 0 0 0]\n",
            "  [1 1 1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 1 1 1 0]\n",
            "  [1 1 1 1 1 1 1 1 1 1]]\n",
            "\n",
            " [[1 0 0 0 0 0 0 0 0 0]\n",
            "  [1 1 0 0 0 0 0 0 0 0]\n",
            "  [1 1 1 0 0 0 0 0 0 0]\n",
            "  [1 1 1 1 0 0 0 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0 0 0]\n",
            "  [1 1 1 1 1 1 0 0 0 0]\n",
            "  [1 1 1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 1 1 1 0]\n",
            "  [1 1 1 1 1 1 1 1 1 1]]], shape=(2, 10, 10), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "@tf.keras.utils.register_keras_serializable(\"positional_embedding\")\n",
        "\n",
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.token_embeddings =tf.keras.layers.Embedding(\n",
        "            input_dim=self.input_dim, output_dim=self.output_dim\n",
        "        )\n",
        "        # position embeddings: syntactic (spatial/temporal) information\n",
        "        self.position_embeddings =tf.keras.layers.Embedding(\n",
        "            input_dim=self.sequence_length, output_dim=self.output_dim\n",
        "        )\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # token embeddings: semantic information\n",
        "        self.token_embeddings =tf.keras.layers.Embedding(\n",
        "            input_dim=self.input_dim, output_dim=self.output_dim\n",
        "        )\n",
        "        # position embeddings: syntactic (spatial/temporal) information\n",
        "        self.position_embeddings =tf.keras.layers.Embedding(\n",
        "            input_dim=self.sequence_length, output_dim=self.output_dim\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        positions = tf.range(start=0, limit=length, delta=1) # delta: step size\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        # both embeddings are simply added together!\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return self.token_embeddings.compute_mask(inputs, mask=mask)\n",
        "\n",
        "    def get_config(self): # retrieve config as a dict\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "def get_causal_attention_mask(inputs):\n",
        "    print(\"Inputs:\")\n",
        "    print(inputs)\n",
        "    print()\n",
        "    input_shape = tf.shape(inputs)\n",
        "    batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "    i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "    j = tf.range(sequence_length)\n",
        "    print(f\"i:\\n{i}\")\n",
        "    print()\n",
        "    print(f\"j:\\n{j}\")\n",
        "    print()\n",
        "    mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "    print(\"Is i >= j? Boolean cast to ints. (Note the broadcasting)\")\n",
        "    print()\n",
        "    print(mask)\n",
        "    print()\n",
        "    mask = tf.reshape(mask, (1, input_shape[1], input_shape[1])) # adding a batch dimension\n",
        "    mult = tf.concat(\n",
        "        [tf.expand_dims(batch_size, -1),\n",
        "         tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "    print(\"We want mask to have the same dims as input, using `tf.tile`.\")\n",
        "    print(\"Creating the right multiplier for it:\")\n",
        "    print()\n",
        "    print(mult)\n",
        "    print()\n",
        "    tile = tf.tile(mask, mult)\n",
        "    print(\"Final mask with batch dimensions:\")\n",
        "    print()\n",
        "    print(tile)\n",
        "    return tile\n",
        "\n",
        "mask = get_causal_attention_mask(tf.random.uniform(shape=(2,10), maxval=50, dtype=tf.int32))\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(\"transformer_decoder\")\n",
        "class TransformerDecoder(tf.keras.layers.Layer):\n",
        "\n",
        "    # simplified class: we don't need two attention layers as we don't have data\n",
        "    # flowing from an encoder!\n",
        "\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim                              # parameters\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.supports_masking = True                            # MASK: enforcing causality\n",
        "\n",
        "    # new in Keras 3, see: https://keras.io/guides/making_new_layers_and_models_via_subclassing/#best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known\n",
        "    def build(self, input_shape):\n",
        "        self.attention_1 = tf.keras.layers.MultiHeadAttention(  # multi-head attention\n",
        "            num_heads=self.num_heads, key_dim=self.embed_dim\n",
        "        )\n",
        "        self.dense_proj = tf.keras.Sequential(                  # dense layer on top: like a nonlinearity\n",
        "            [tf.keras.layers.Dense(self.dense_dim, activation=\"relu\"),\n",
        "             tf.keras.layers.Dense(self.embed_dim),\n",
        "             tf.keras.layers.Dropout(0.1)]\n",
        "        )\n",
        "        self.layernorm_1 = tf.keras.layers.LayerNormalization() # layer norm\n",
        "        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "\n",
        "    # retrieve config as a dict (necessary for custom Keras layers)\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "\n",
        "        # prepare the causal mask\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "\n",
        "        # REGULAR MASKED ATTENTION\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask) # apply the causal mask\n",
        "\n",
        "        # residual / layer norm\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        # dense net / nonlinearity layer norm /\n",
        "        proj_output = self.layernorm_2(self.dense_proj(attention_output_1))\n",
        "\n",
        "        # residual\n",
        "        return attention_output_1 + proj_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0a72947a-ee55-4dd6-9611-e0f7ef960a55",
      "metadata": {
        "id": "0a72947a-ee55-4dd6-9611-e0f7ef960a55"
      },
      "outputs": [],
      "source": [
        "EMBED_DIM = 256\n",
        "LATENT_DIM = 2048\n",
        "NUM_HEADS = 2\n",
        "NUM_LAYERS = 5\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "def build_model(embed_dim, latent_dim, num_heads, num_layers):\n",
        "    inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "    x = PositionalEmbedding(SEQUENCE_LENGTH, VOCAB_SIZE, embed_dim)(inputs)\n",
        "    for _ in range(num_layers):\n",
        "        x = TransformerDecoder(embed_dim, latent_dim, num_heads)(inputs=x) # no encoder input!\n",
        "    outputs =tf.keras.layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)    # probability distribution over the vocab\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.RMSprop(LEARNING_RATE),\n",
        "        metrics= [\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model1 = build_model(EMBED_DIM, LATENT_DIM, NUM_HEADS, NUM_LAYERS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_next(predictions, temperature=1.0):\n",
        "    predictions = np.asarray(predictions).astype(\"float64\")\n",
        "    predictions = np.log(predictions) / temperature                 # temperature reweighting\n",
        "    exp_preds = np.exp(predictions)                                 # these two lines are actually\n",
        "    predictions = exp_preds / np.sum(exp_preds)                     # a softmax\n",
        "    probas = np.random.multinomial(1, predictions, 1)               # sampling using our probabilities\n",
        "    return np.argmax(probas)\n",
        "\n",
        "class TextGenerator(tf.keras.callbacks.Callback):\n",
        "    def __init__(self,\n",
        "                 prompt,                                            # initial context\n",
        "                 generate_length,                                   # how many words to generate\n",
        "                 seq_length,\n",
        "                 temperatures=(1.,),                                # a range of different temperatures\n",
        "                 print_every=50):\n",
        "        self.prompt = prompt\n",
        "        self.generate_length = generate_length\n",
        "        self.seq_length = seq_length\n",
        "        self.temperatures = temperatures\n",
        "        self.print_every = print_every\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch == 0 or (epoch + 1) % self.print_every == 0:\n",
        "            print()\n",
        "            print()\n",
        "            print(\"EPOCH\", epoch + 1)\n",
        "            print()\n",
        "            print(\"-\" * 40)\n",
        "            for temperature in self.temperatures:\n",
        "                msg = f\"temperature {temperature}\"\n",
        "                print(msg)\n",
        "                print(\"-\" * len(msg))\n",
        "                sentence = self.prompt                                                      # start with our prompt\n",
        "                for i in range(self.generate_length):\n",
        "                    tokenized_sentence = text_vectorization([sentence])                     # encode the sentence & feed to the model\n",
        "                    predictions = self.model(tokenized_sentence[:, - self.seq_length + 1:]) # which gives us predictions (crop to seq_len!)\n",
        "                    next_token = sample_next(predictions[0, -1, :])                         # use these to sample (get the index)\n",
        "                    sampled_token = TOKEN_INDEX[next_token]                                # use the index to pick the token\n",
        "                    sentence += sampled_token                                               # add it to our sentence\n",
        "                print(sentence)\n",
        "                print()\n",
        "            print(\"-\" * 40)\n"
      ],
      "metadata": {
        "id": "nlj3RYKp5sia"
      },
      "id": "nlj3RYKp5sia",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "model1.fit(\n",
        "    lm_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=DATASET_LENGTH // (SEQUENCE_LENGTH + 1) // BATCH_SIZE,\n",
        "    # callbacks=[text_gen_callback, ckpt_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "vicMAokx8uEB"
      },
      "id": "vicMAokx8uEB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "model1.fit(\n",
        "    lm_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=DATASET_LENGTH // (SEQUENCE_LENGTH + 1) // BATCH_SIZE,\n",
        "    # callbacks=[text_gen_callback, ckpt_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3baLVB0TUuD",
        "outputId": "ca54bdb8-2a00-4b46-f4e4-408f958dc02d"
      },
      "id": "e3baLVB0TUuD",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 119ms/step - accuracy: 0.7642 - loss: 0.7135\n",
            "Epoch 2/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7605 - loss: 0.7238\n",
            "Epoch 3/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.7627 - loss: 0.7185\n",
            "Epoch 4/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.7646 - loss: 0.7112\n",
            "Epoch 5/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7673 - loss: 0.7020\n",
            "Epoch 6/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7697 - loss: 0.6969\n",
            "Epoch 7/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.7720 - loss: 0.6875\n",
            "Epoch 8/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.7742 - loss: 0.6814\n",
            "Epoch 9/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.7763 - loss: 0.6745\n",
            "Epoch 10/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7790 - loss: 0.6668\n",
            "Epoch 11/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7812 - loss: 0.6606\n",
            "Epoch 12/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7830 - loss: 0.6531\n",
            "Epoch 13/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.7855 - loss: 0.6459\n",
            "Epoch 14/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7869 - loss: 0.6394\n",
            "Epoch 15/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7889 - loss: 0.6347\n",
            "Epoch 16/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7916 - loss: 0.6262\n",
            "Epoch 17/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7933 - loss: 0.6206\n",
            "Epoch 18/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7961 - loss: 0.6131\n",
            "Epoch 19/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7970 - loss: 0.6074\n",
            "Epoch 20/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.7999 - loss: 0.6003\n",
            "Epoch 21/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8005 - loss: 0.5967\n",
            "Epoch 22/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8036 - loss: 0.5877\n",
            "Epoch 23/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8058 - loss: 0.5806\n",
            "Epoch 24/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.8063 - loss: 0.5797\n",
            "Epoch 25/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8085 - loss: 0.5719\n",
            "Epoch 26/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8113 - loss: 0.5639\n",
            "Epoch 27/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.8132 - loss: 0.5598\n",
            "Epoch 28/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.8149 - loss: 0.5514\n",
            "Epoch 29/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 113ms/step - accuracy: 0.8171 - loss: 0.5456\n",
            "Epoch 30/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8190 - loss: 0.5402\n",
            "Epoch 31/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8195 - loss: 0.5368\n",
            "Epoch 32/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8214 - loss: 0.5313\n",
            "Epoch 33/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 113ms/step - accuracy: 0.8241 - loss: 0.5248\n",
            "Epoch 34/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 113ms/step - accuracy: 0.8252 - loss: 0.5208\n",
            "Epoch 35/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8273 - loss: 0.5127\n",
            "Epoch 36/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8291 - loss: 0.5083\n",
            "Epoch 37/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8301 - loss: 0.5043\n",
            "Epoch 38/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 113ms/step - accuracy: 0.8316 - loss: 0.4999\n",
            "Epoch 39/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.8343 - loss: 0.4918\n",
            "Epoch 40/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8351 - loss: 0.4883\n",
            "Epoch 41/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.8364 - loss: 0.4841\n",
            "Epoch 42/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8391 - loss: 0.4770\n",
            "Epoch 43/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8402 - loss: 0.4734\n",
            "Epoch 44/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8419 - loss: 0.4686\n",
            "Epoch 45/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.8434 - loss: 0.4635\n",
            "Epoch 46/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8446 - loss: 0.4608\n",
            "Epoch 47/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8461 - loss: 0.4544\n",
            "Epoch 48/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8479 - loss: 0.4503\n",
            "Epoch 49/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.8483 - loss: 0.4474\n",
            "Epoch 50/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - accuracy: 0.8511 - loss: 0.4404\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eb7043b8610>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('hemingway.keras')\n",
        "# load = tf.keras.models.load_model('../content/hemingway.keras')\n",
        "# load.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "-n2S8IPQVD8P",
        "outputId": "6fbefcee-8574-4fb2-fef9-0781ab231df8"
      },
      "id": "-n2S8IPQVD8P",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 86 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ positional_embedding                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │          \u001b[38;5;34m40,704\u001b[0m │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)                │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m1,577,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m1,577,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m1,577,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m1,577,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m1,577,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)            │          \u001b[38;5;34m15,163\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ positional_embedding                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">40,704</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)                │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,163</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,891,576\u001b[0m (60.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,891,576</span> (60.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,945,787\u001b[0m (30.31 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,945,787</span> (30.31 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m7,945,789\u001b[0m (30.31 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,945,789</span> (30.31 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(sentence=\" \", generate_length=100, temperature=1.):\n",
        "  for i in range(generate_length):\n",
        "      tokenized_sentence = text_vectorization([sentence])                       # encode the sentence & feed to the model\n",
        "      predictions = model(tokenized_sentence[:, - SEQUENCE_LENGTH + 1:])        # which gives us predictions  (crop to seq_len!)\n",
        "      next_token = sample_next(predictions[0, -1, :], temperature)              # use these to sample (get the index)\n",
        "      sampled_token = TOKEN_INDEX[next_token]                                   # use the index to pick the token\n",
        "      sentence += sampled_token\n",
        "      if len(sentence.split()) == 17:\n",
        "        break\n",
        "  return sentence\n",
        "\n",
        "def outputhaiku(sentence):\n",
        "  nlwords = ['i','he', 'she', 'it', 'they', 'for', 'and', 'nor', 'but', 'or', 'yet', 'so', 'the']  # list of linking and transition words\n",
        "  words = sentence.split()\n",
        "  count = 0\n",
        "  lineone = \"\"\n",
        "  linetwo = \"\"\n",
        "  linethree = \"\"\n",
        "  while len(lineone.split()) != 5:\n",
        "    if words[count] in nlwords and len(lineone.split()) > 2:\n",
        "      break\n",
        "    lineone += words[count] + \" \"\n",
        "    count += 1\n",
        "  print(lineone)\n",
        "  while len(linetwo.split()) != 7:\n",
        "    if words[count] in nlwords and len(linetwo.split()) >2:\n",
        "      break\n",
        "    linetwo += words[count] + \" \"\n",
        "    count += 1\n",
        "  print(linetwo)\n",
        "  while len(linethree.split()) != 5:\n",
        "    if words[count] in nlwords and len(linethree.split()) > 2:\n",
        "      break\n",
        "    linethree += words[count] + \" \"\n",
        "    count += 1\n",
        "  print(linethree)"
      ],
      "metadata": {
        "id": "ku7y2rOlRubw"
      },
      "id": "ku7y2rOlRubw",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = generate(sentence=\"summer \", generate_length=100, temperature=0.5)\n",
        "print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFfdu2s1YQlz",
        "outputId": "f5c7fc1b-eeb3-4df4-ca95-a5a7513b872d"
      },
      "id": "jFfdu2s1YQlz",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summer eeeepàeejaeeeerçep1âep\n",
            "nöeeer6îpàeeeeeeîjöepàeeeeeeeepöa\n",
            "eparesüepeàp\n",
            "öeeeeeereeàeeeeeeàerçeóacneóöe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Generating initial results"
      ],
      "metadata": {
        "id": "8iko7U8uL_6c"
      },
      "id": "8iko7U8uL_6c"
    },
    {
      "cell_type": "code",
      "source": [
        "outputhaiku(sentence=sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "pM_bWtrE86T0",
        "outputId": "37297cd8-a1b6-4073-ea7a-a9440bee87f8"
      },
      "id": "pM_bWtrE86T0",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summer eeeepàeejaeeeerçep1âep nöeeer6îpàeeeeeeîjöepàeeeeeeeepöa eparesüepeàp öeeeeeereeàeeeeeeàerçeóacneóöe \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-e85e3cc0e8b8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputhaiku\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-2ce0a757dd5a>\u001b[0m in \u001b[0;36moutputhaiku\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlineone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinetwo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinetwo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlinetwo\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Different approach\n",
        "\n",
        "Implementing GloVe embeddings with a simple LSTM model"
      ],
      "metadata": {
        "id": "LvwNfKeyLv0e"
      },
      "id": "LvwNfKeyLv0e"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove"
      ],
      "metadata": {
        "id": "E0Iud6RjMNIk"
      },
      "id": "E0Iud6RjMNIk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_DIM = 256\n",
        "LATENT_DIM = 2048\n",
        "NUM_HEADS = 2\n",
        "NUM_LAYERS = 5\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "def build_model(embed_dim, latent_dim, num_heads, num_layers):\n",
        "    inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "    x = PositionalEmbedding(SEQUENCE_LENGTH, VOCAB_SIZE, embed_dim)(inputs)\n",
        "    for _ in range(num_layers):\n",
        "        x = TransformerDecoder(embed_dim, latent_dim, num_heads)(inputs=x) # no encoder input!\n",
        "    outputs =tf.keras.layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)    # probability distribution over the vocab\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
        "        metrics= [\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_model(EMBED_DIM, LATENT_DIM, NUM_HEADS, NUM_LAYERS)"
      ],
      "metadata": {
        "id": "DWTAI6NFMYES"
      },
      "id": "DWTAI6NFMYES",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}